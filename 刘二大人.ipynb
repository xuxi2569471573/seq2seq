{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用RnnCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 2, 3]\n",
    "y_data = [3, 1, 2, 3, 2]#ohlol\n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                    [0, 1, 0, 0],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnncell = torch.nn.RNNCell(input_size=self.input_size,\n",
    "                hidden_size=self.hidden_size)\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.rnncell(input, hidden)\n",
    "        return hidden\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "net = Model(input_size, hidden_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string: "
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = net.init_hidden()\n",
    "    print('Predicted string: ', end='')\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden = net(input, hidden)#[1, 4],[1, 4] ->[1, 4]\n",
    "        loss += criterion(hidden, label)\n",
    "        _, idx = hidden.max(dim=1)\n",
    "        print(idx2char[idx.item()], end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,batch_size,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = torch.nn.RNN(input_size,hidden_size,num_layers)\n",
    "    def forward(self,input):\n",
    "        hidden = torch.zeros((self.num_layers,self.batch_size,self.hidden_size))\n",
    "        output,hidden = self.rnn(input,hidden)#[5, 1, 4],[1, 1, 4] ->[5,1,4],[1, 1, 4]\n",
    "        return output.permute(1,2,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "net = Model(input_size, hidden_size, batch_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1839, -0.4537, -0.2574, -0.1384,  0.3776],\n",
       "          [-0.4430, -0.2907,  0.5403,  0.3733,  0.3725],\n",
       "          [-0.4269, -0.0384, -0.7657, -0.7928, -0.6674],\n",
       "          [-0.1535,  0.3500,  0.5106,  0.2585,  0.2497]]],\n",
       "        grad_fn=<PermuteBackward>),\n",
       " torch.Size([1, 4, 5]),\n",
       " torch.Size([1, 5]),\n",
       " array([[3, 3, 1, 1, 0]], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 2, 3]\n",
    "y_data = [3, 1, 2, 3, 2]#ohlol\n",
    "one_hot_lookup = [[1, 0, 0, 0],\n",
    "                    [0, 1, 0, 0],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data).view(batch_size, -1)\n",
    "out = net(inputs)\n",
    "_,idx = out.max(dim=1)\n",
    "\n",
    "out,out.shape,labels.shape,idx.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  oohhe, Epoch [1/15] loss = 1.704\n",
      "Predicted:  ooooo, Epoch [2/15] loss = 1.592\n",
      "Predicted:  ooooo, Epoch [3/15] loss = 1.477\n",
      "Predicted:  ooooo, Epoch [4/15] loss = 1.353\n",
      "Predicted:  ooooo, Epoch [5/15] loss = 1.226\n",
      "Predicted:  ohooo, Epoch [6/15] loss = 1.109\n",
      "Predicted:  ohool, Epoch [7/15] loss = 1.011\n",
      "Predicted:  ohool, Epoch [8/15] loss = 0.934\n",
      "Predicted:  ohlol, Epoch [9/15] loss = 0.875\n",
      "Predicted:  ohlol, Epoch [10/15] loss = 0.827\n",
      "Predicted:  ohlol, Epoch [11/15] loss = 0.783\n",
      "Predicted:  ohlol, Epoch [12/15] loss = 0.741\n",
      "Predicted:  ohlol, Epoch [13/15] loss = 0.701\n",
      "Predicted:  ohlol, Epoch [14/15] loss = 0.662\n",
      "Predicted:  ohlol, Epoch [15/15] loss = 0.627\n",
      "Predicted:  ohlol, Epoch [16/15] loss = 0.595\n",
      "Predicted:  ohlol, Epoch [17/15] loss = 0.566\n",
      "Predicted:  ohlol, Epoch [18/15] loss = 0.541\n",
      "Predicted:  ohlol, Epoch [19/15] loss = 0.519\n",
      "Predicted:  ohlol, Epoch [20/15] loss = 0.499\n",
      "Predicted:  ohlol, Epoch [21/15] loss = 0.481\n",
      "Predicted:  ohlol, Epoch [22/15] loss = 0.466\n",
      "Predicted:  ohlol, Epoch [23/15] loss = 0.452\n",
      "Predicted:  ohlol, Epoch [24/15] loss = 0.441\n",
      "Predicted:  ohlol, Epoch [25/15] loss = 0.432\n",
      "Predicted:  ohlol, Epoch [26/15] loss = 0.423\n",
      "Predicted:  ohlol, Epoch [27/15] loss = 0.416\n",
      "Predicted:  ohlol, Epoch [28/15] loss = 0.410\n",
      "Predicted:  ohlol, Epoch [29/15] loss = 0.404\n",
      "Predicted:  ohlol, Epoch [30/15] loss = 0.400\n",
      "Predicted:  ohlol, Epoch [31/15] loss = 0.396\n",
      "Predicted:  ohlol, Epoch [32/15] loss = 0.393\n",
      "Predicted:  ohlol, Epoch [33/15] loss = 0.391\n",
      "Predicted:  ohlol, Epoch [34/15] loss = 0.390\n",
      "Predicted:  ohlol, Epoch [35/15] loss = 0.388\n",
      "Predicted:  ohlol, Epoch [36/15] loss = 0.386\n",
      "Predicted:  ohlol, Epoch [37/15] loss = 0.384\n",
      "Predicted:  ohlol, Epoch [38/15] loss = 0.382\n",
      "Predicted:  ohlol, Epoch [39/15] loss = 0.381\n",
      "Predicted:  ohlol, Epoch [40/15] loss = 0.379\n",
      "Predicted:  ohlol, Epoch [41/15] loss = 0.377\n",
      "Predicted:  ohlol, Epoch [42/15] loss = 0.376\n",
      "Predicted:  ohlol, Epoch [43/15] loss = 0.375\n",
      "Predicted:  ohlol, Epoch [44/15] loss = 0.374\n",
      "Predicted:  ohlol, Epoch [45/15] loss = 0.373\n",
      "Predicted:  ohlol, Epoch [46/15] loss = 0.373\n",
      "Predicted:  ohlol, Epoch [47/15] loss = 0.372\n",
      "Predicted:  ohlol, Epoch [48/15] loss = 0.371\n",
      "Predicted:  ohlol, Epoch [49/15] loss = 0.371\n",
      "Predicted:  ohlol, Epoch [50/15] loss = 0.370\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()[0]\n",
    "    print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss = %.3f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入嵌入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,embedding_size,num_class,batch_size,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.emb = torch.nn.Embedding(input_size,embedding_size)\n",
    "        self.rnn = torch.nn.GRU(embedding_size,hidden_size,num_layers)\n",
    "        self.fc = torch.nn.Linear(hidden_size,num_class)\n",
    "    def forward(self,input):\n",
    "        hidden = torch.zeros((self.num_layers,self.batch_size,self.hidden_size))\n",
    "        input = self.emb(input)\n",
    "        input = input.permute(1,0,2)\n",
    "        output,hidden = self.rnn(input,hidden)\n",
    "        output = self.fc(output)\n",
    "        return output.permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 4\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "embedding_size = 10\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "net = Model(input_size,hidden_size,embedding_size,num_class,batch_size,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2390, -0.2747, -0.2483, -0.1974, -0.1640],\n",
       "          [ 0.2475,  0.2623,  0.2835,  0.3037,  0.3067],\n",
       "          [-0.0921, -0.0486, -0.0689, -0.0762, -0.0331],\n",
       "          [-0.1449, -0.1646, -0.2391, -0.3194, -0.3411]]],\n",
       "        grad_fn=<PermuteBackward>),\n",
       " torch.Size([1, 4, 5]),\n",
       " torch.Size([1, 5]),\n",
       " array([[4, 4, 4, 0]], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 2, 3]\n",
    "y_data = [3, 1, 2, 3, 2]#ohlol\n",
    "inputs = torch.LongTensor(x_data).view(batch_size,-1)\n",
    "labels = torch.LongTensor(y_data).view(batch_size,-1)\n",
    "out = net(inputs)\n",
    "_,idx = out.max(dim=2)\n",
    "\n",
    "out,out.shape,labels.shape,idx.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()[0]\n",
    "    print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss = %.3f' % (epoch + 1, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "985a0f387c27ff784145167e4daf92db03db1d9b0a87f6ca13a539e928ea05de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
